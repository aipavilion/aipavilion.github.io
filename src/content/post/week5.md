+++
date = "01 Oct 2018"
draft = false
title = "Week 5: Papers and Purpose"
slug = "week4"
+++

## Talk this Friday

[John C. Havens](http://www.johnchavens.com/) will be speaking on Friday (Oct 5), 10-11:30am on _Humanities, Cultures and Ethics in the Era of AI_, Wilson Hall 301. He is executive director of the IEEE project on [Ethics of Autonomous and Intelligent Systems](https://ethicsinaction.ieee.org/).

Use [this link](https://drive.google.com/open?id=1_JEklX4-NJ1lw4fm6WpJ9rwQK9kw5gPzYwOIfcGXF-A) to RSVP (there is also a lunch following the talk).

## Interesting Law

California passed a law about bots impersonating humans: [Senate Bill No. 1001: Bots: disclosure](http://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1001)

> 17941. (a) It shall be unlawful for any person to use a bot to communicate or interact with another person in California online, with the intent to mislead the other person about its artificial identity for the purpose of knowingly deceiving the person about the content of the communication in order to incentivize a purchase or sale of goods or services in a commercial transaction or to influence a vote in an election. A person using a bot shall not be liable under this section if the person discloses that it is a bot.  
> (b) The disclosure required by this section shall be clear, conspicuous, and reasonably designed to inform persons with whom the bot communicates or interacts that it is a bot.

It is interesting that it seems to be unlawful for a bot to
intentionally confuse a human, but not for a bot to intentionally
confuse another machine (which is a much more common problem in
actuality today).

## Reading Assignment

Because of fall break, there is no meeting next week. The next major
readings we will do are from Nick Bostrom's _Superintelligence_
[[Amazon](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom-dp-0198739834/dp/0198739834/)]. We
won't read all of this, but will read many chapters. Tim Urban's
("Wait but why"), <a
href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html"><em>The
AI Revolution: The Road to Superintelligence</em></a> is largely based
on this book, but the book goes into more depth on many points.

By October 15, you should do at least one of these two things:

**Option 1:** Watch [Nick Bostrom's talk at
Google](https://www.youtube.com/watch?v=pywF6ZzsghI) (Sep 2014). (You
should definitely watch the question and answer period at the end of
the talk --- the first question is from Ray Kurzweil, the third is
Peter Norvig.) and Read Chapter 3 of _Superintelligence_.

**Option 2:** Read Chapters 1-4 of _Superintelligence_. 

This is a (relatively) short reading assignment for the two weeks you
have, to provide time to focus on your papers (the first draft of
which is due on **Wednesday, October 17**.)

## Responses

Either (1) select at least one of the questions below and post a
comment on the course forum, (2) respond to a comment someone else
posted, or (3) post your own thoughts on something in either the talk
or readings. [[Link to Post]](https://redd.it/9l7kkw)

**1.** Bostrom talks and writes about using biological enhancement through
genetic selection, but many people find such an idea distasteful at
best or dystopian at worst. According to a 2004 poll reported in book,
28% of Americans approved of embryo selection for "strength of
intelligence", 68% for avoiding fatal childhood disease. A [more
recent survey](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4429433/)
found 70% support for PGD selection for avoiding diseases fatal early
in life or lifelong disability, 48% for diseases that manifest late in
life, 21% for sex selection, 14.6% for physical traits, and 18.9% for
personality traits. These responses suggest some kind of moral or
practical difference between different types of embryo selection. Is
there a way to decide what kinds of embryo selection are moral? What
kinds should be disallowed, and what is the justification?

**2.** Bostrom writes about an internet with "better support for
deliberation, de-biasing, and judgment aggregation, might make large
contributions to increasing the collective intelligence of
humanity". Is this realistic? What would be necessary to move from
what we have now to an internet that increases collective
intelligence?

**3.** Bostrom defines "superintelligence" as "intellects that greatly
outperform the best current human minds across many very general
cognitive domains", but doesn't provide any concrete or satisfying
definition (in my view). A better definition might make specific
claims about what problems a superintelligence could solve, or what
behaviors it would have. Suggest a better definition (or make a case
in support of Bostrom's definition).



